{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import deepl\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv() \n",
    "\n",
    "# df = pd.read_excel('data/nlmyo/processed/diag.xlsx')\n",
    "# # Read the text content from the filename column and add it to a new column\n",
    "# df[\"filepath\"] = df[\"filename\"].apply(lambda x: \"data/nlmyo/processed/\" + x)\n",
    "# df['raw_text'] = df['filepath'].apply(lambda x: open(x, 'r').read())\n",
    "\n",
    "\n",
    "# translator = deepl.Translator(os.getenv(\"DEEPL_KEY\")) \n",
    "# df['deepl_translation'] = df['raw_text'].apply(lambda x: translator.translate_text(x, target_lang=\"EN-US\").text)\n",
    "# save df to csv file\n",
    "# df.to_csv('data/nlmyo/processed/diag_translated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from embetter.external import CohereEncoder, OpenAIEncoder\n",
    "from embetter.grab import ColumnGrabber\n",
    "from sklearn.pipeline import make_pipeline \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from cohere import Client\n",
    "\n",
    "# load_dotenv() \n",
    "# client = Client(os.getenv(\"COHERE_KEY\"))\n",
    "# # This pipeline grabs the `text` column from a dataframe\n",
    "\n",
    "# df = pd.read_csv('data/nlmyo/processed/diag_translated.csv')\n",
    "\n",
    "# text_emb_pipeline = make_pipeline(\n",
    "#   ColumnGrabber(\"deepl_translation\"),\n",
    "#   CohereEncoder(client=client, model=\"large\")\n",
    "# )\n",
    "\n",
    "# X = text_emb_pipeline.fit_transform(df, df['diag_simple'])\n",
    "# np.save('data/nlmyo/processed/report_translated_embed_cohere.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from embetter.external import CohereEncoder, OpenAIEncoder\n",
    "from embetter.grab import ColumnGrabber\n",
    "from sklearn.pipeline import make_pipeline \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "# load_dotenv() \n",
    "\n",
    "# openai.organization = os.getenv(\"OPENAI_ORG\")\n",
    "# openai.api_key = os.getenv(\"OPENAI_KEY\")\n",
    "# # This pipeline grabs the `text` column from a dataframe\n",
    "\n",
    "# df = pd.read_csv('data/nlmyo/processed/diag_translated.csv')\n",
    "\n",
    "# text_emb_pipeline = make_pipeline(\n",
    "#   ColumnGrabber(\"deepl_translation\"),\n",
    "#   OpenAIEncoder(model=\"text-embedding-ada-002\")\n",
    "# )\n",
    "\n",
    "# X = text_emb_pipeline.fit_transform(df, df['diag_simple'])\n",
    "# np.save('data/nlmyo/processed/report_translated_embed_openai.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nermaline Myopathy        37\n",
       "Core Myopathy             37\n",
       "UNCLEAR                   37\n",
       "Centronuclear Myopathy    12\n",
       "NON-MC                    11\n",
       "CFTD                       2\n",
       "Name: diag_simple, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/nlmyo/processed/diag_translated.csv')\n",
    "df['diag_simple'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 4096)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cohere.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#### Import the data\n",
    "df = pd.read_csv('data/nlmyo/processed/diag_translated.csv')\n",
    "Y = df['diag_simple'].values\n",
    "X_cohere = np.load('data/nlmyo/processed/report_translated_embed_cohere.npy') \n",
    "X_openai = np.load('data/nlmyo/processed/report_translated_embed_openai.npy')\n",
    "\n",
    "# Remove CFTD and unclear diagnosis\n",
    "df['diag_simple'].value_counts()\n",
    "df['diag_simple'] = df['diag_simple'].replace('CFTD', 'UNCLEAR')\n",
    "# Drop the rows with unclear diagnosis\n",
    "df = df[df['diag_simple'] != 'UNCLEAR']\n",
    "Y = df['diag_simple'].values\n",
    "# Do the same for the X array based on the df index\n",
    "X_cohere = X_cohere[df.index]\n",
    "X_openai = X_openai[df.index]\n",
    "cv_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Results:\n",
      "All CV Scores: [0.4        0.4        0.4        0.4        0.3        0.3\n",
      " 0.3        0.33333333 0.33333333 0.33333333]\n",
      "Mean CV Score:  0.35000000000000003\n",
      "Standard Deviation CV Score: 0.04281744192888378\n"
     ]
    }
   ],
   "source": [
    "clf_dummy = DummyClassifier(strategy='prior')\n",
    "cv_scores_dummy = cross_val_score(clf_dummy, X_cohere, Y, cv=cv_fold)\n",
    "print(\"Dummy Classifier Results:\")\n",
    "print(f\"All CV Scores: {cv_scores_dummy}\")\n",
    "print(f\"Mean CV Score:  {np.mean(cv_scores_dummy)}\")\n",
    "print(f\"Standard Deviation CV Score: {np.std(cv_scores_dummy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Logistic Regression and Cohere Embeddings on English Translated Reports:\n",
      "All CV Scores: [0.6        0.7        0.6        0.5        0.6        0.5\n",
      " 0.7        0.55555556 0.66666667 0.77777778]\n",
      "Mean CV Score:  0.62\n",
      "Standard Deviation CV Score: 0.08603760303380416\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=3000)\n",
    "cv_scores = cross_val_score(clf, X_cohere, Y, cv=cv_fold)\n",
    "print(\"Results with Logistic Regression and Cohere Embeddings on English Translated Reports:\")\n",
    "print(f\"All CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score:  {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation CV Score: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Logistic Regression and OpenAI Embeddings on English Translated Reports:\n",
      "All CV Scores: [0.6        0.4        0.6        0.6        0.5        0.5\n",
      " 0.6        0.77777778 0.44444444 0.66666667]\n",
      "Mean CV Score:  0.5688888888888889\n",
      "Standard Deviation CV Score: 0.10515127257174203\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=3000)\n",
    "cv_scores = cross_val_score(clf, X_openai, Y, cv=cv_fold)\n",
    "print(\"Results with Logistic Regression and OpenAI Embeddings on English Translated Reports:\")\n",
    "print(f\"All CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Score:  {np.mean(cv_scores)}\")\n",
    "print(f\"Standard Deviation CV Score: {np.std(cv_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([('clf', DummyEstimator())]) # Placeholder Estimator\n",
    "\n",
    "# Candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'clf': [LogisticRegression()],\n",
    "                    'clf__max_iter': [1500]},\n",
    "                {'clf': [GaussianNB()],},\n",
    "                {'clf': [MLPClassifier()],\n",
    "                 'clf__max_iter': [500]},\n",
    "                {'clf': [KNeighborsClassifier()],},\n",
    "                {'clf': [SVC()],},\n",
    "                {'clf': [GaussianProcessClassifier()],},\n",
    "                {'clf': [HistGradientBoostingClassifier()],},\n",
    "                {'clf': [DecisionTreeClassifier()],},\n",
    "                {'clf': [RandomForestClassifier()],},\n",
    "                {'clf': [AdaBoostClassifier()],},\n",
    "                ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search \n",
    "gs = GridSearchCV(pipe, search_space, scoring=\"accuracy\", cv=cv_fold)\n",
    "gs.fit(X_cohere, Y)\n",
    "df_cv_search = pd.DataFrame(gs.cv_results_)\n",
    "df_cv_search.to_csv('data/nlmyo/processed/report_translated_embed_cohere_gridsearch.csv')\n",
    "df_cv_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1500</td>\n",
       "      <td>{'clf': LogisticRegression(), 'clf__max_iter':...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.568889</td>\n",
       "      <td>0.105151</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>GaussianNB()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': GaussianNB()}</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.162272</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.746184</td>\n",
       "      <td>0.364329</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>MLPClassifier(max_iter=1000)</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'clf': MLPClassifier(max_iter=1000), 'clf__ma...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.182996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.016027</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': KNeighborsClassifier()}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.487778</td>\n",
       "      <td>0.172021</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': SVC()}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.106696</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.084241</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.003856</td>\n",
       "      <td>GaussianProcessClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': GaussianProcessClassifier()}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.547778</td>\n",
       "      <td>0.097885</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.456280</td>\n",
       "      <td>0.087878</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.005593</td>\n",
       "      <td>HistGradientBoostingClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': HistGradientBoostingClassifier()}</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.571111</td>\n",
       "      <td>0.166385</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050843</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': DecisionTreeClassifier()}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.423333</td>\n",
       "      <td>0.139704</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.267129</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.014863</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': RandomForestClassifier()}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.137257</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.813311</td>\n",
       "      <td>0.074244</td>\n",
       "      <td>0.010220</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'clf': AdaBoostClassifier()}</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.463333</td>\n",
       "      <td>0.077786</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.038400      0.004094         0.001046        0.000041   \n",
       "1       0.002641      0.000271         0.001127        0.000062   \n",
       "2       2.746184      0.364329         0.001606        0.000231   \n",
       "3       0.001071      0.000153         0.013386        0.016027   \n",
       "4       0.005151      0.001714         0.001672        0.000073   \n",
       "5       0.084241      0.014789         0.011682        0.003856   \n",
       "6       1.456280      0.087878         0.013010        0.005593   \n",
       "7       0.050843      0.013542         0.000726        0.000181   \n",
       "8       0.267129      0.006483         0.014863        0.000295   \n",
       "9       0.813311      0.074244         0.010220        0.000613   \n",
       "\n",
       "                          param_clf param_clf__max_iter  \\\n",
       "0              LogisticRegression()                1500   \n",
       "1                      GaussianNB()                 NaN   \n",
       "2      MLPClassifier(max_iter=1000)                1000   \n",
       "3            KNeighborsClassifier()                 NaN   \n",
       "4                             SVC()                 NaN   \n",
       "5       GaussianProcessClassifier()                 NaN   \n",
       "6  HistGradientBoostingClassifier()                 NaN   \n",
       "7          DecisionTreeClassifier()                 NaN   \n",
       "8          RandomForestClassifier()                 NaN   \n",
       "9              AdaBoostClassifier()                 NaN   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'clf': LogisticRegression(), 'clf__max_iter':...                0.6   \n",
       "1                              {'clf': GaussianNB()}                0.4   \n",
       "2  {'clf': MLPClassifier(max_iter=1000), 'clf__ma...                0.6   \n",
       "3                    {'clf': KNeighborsClassifier()}                0.6   \n",
       "4                                     {'clf': SVC()}                0.5   \n",
       "5               {'clf': GaussianProcessClassifier()}                0.6   \n",
       "6          {'clf': HistGradientBoostingClassifier()}                0.6   \n",
       "7                  {'clf': DecisionTreeClassifier()}                0.5   \n",
       "8                  {'clf': RandomForestClassifier()}                0.5   \n",
       "9                      {'clf': AdaBoostClassifier()}                0.5   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                0.4                0.6                0.6                0.5   \n",
       "1                0.4                0.4                0.4                0.3   \n",
       "2                0.7                0.7                0.7                0.8   \n",
       "3                0.6                0.3                0.5                0.5   \n",
       "4                0.4                0.5                0.4                0.4   \n",
       "5                0.4                0.6                0.6                0.5   \n",
       "6                0.6                0.5                0.4                0.7   \n",
       "7                0.3                0.5                0.7                0.2   \n",
       "8                0.6                0.5                0.7                0.7   \n",
       "9                0.4                0.6                0.5                0.5   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0                0.5                0.6           0.777778           0.444444   \n",
       "1                0.4                0.6           0.888889           0.333333   \n",
       "2                0.2                0.8           0.777778           0.555556   \n",
       "3                0.3                0.3           0.888889           0.444444   \n",
       "4                0.4                0.7           0.666667           0.444444   \n",
       "5                0.4                0.6           0.666667           0.444444   \n",
       "6                0.2                0.6           0.777778           0.555556   \n",
       "7                0.3                0.4           0.555556           0.333333   \n",
       "8                0.4                0.6           0.888889           0.666667   \n",
       "9                0.4                0.4           0.555556           0.444444   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.666667         0.568889        0.105151                4  \n",
       "1           0.444444         0.456667        0.162272                9  \n",
       "2           0.888889         0.672222        0.182996                1  \n",
       "3           0.444444         0.487778        0.172021                7  \n",
       "4           0.555556         0.496667        0.106696                6  \n",
       "5           0.666667         0.547778        0.097885                5  \n",
       "6           0.777778         0.571111        0.166385                3  \n",
       "7           0.444444         0.423333        0.139704               10  \n",
       "8           0.777778         0.633333        0.137257                2  \n",
       "9           0.333333         0.463333        0.077786                8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create grid search \n",
    "gs = GridSearchCV(pipe, search_space, scoring=\"accuracy\", cv=cv_fold)\n",
    "gs.fit(X_openai, Y)\n",
    "df_cv_search = pd.DataFrame(gs.cv_results_)\n",
    "df_cv_search.to_csv('data/nlmyo/processed/report_translated_embed_cohere_gridsearch.csv')\n",
    "df_cv_search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72f151f06f73a7f1387c41c20c6e81dd1f2de7c0f647fc647e5076786050674c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
